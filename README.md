# Taller AI Generativa
Este repositorio contiene el material y el c√≥digo del taller ‚ÄúOptimizaci√≥n de la Atenci√≥n al Cliente en E-commerce con IA Generativa‚Äù, basado en el caso de estudio de la empresa ficticia "EcoMarket".


# Fase 1 ‚Äì Selecci√≥n y Justificaci√≥n del Modelo de IA

## 1Ô∏è‚É£ Tipo de modelo propuesto
Optar√≠a por un **LLM de prop√≥sito general** , en este caso el *Llama 3* combinado con un enfoque de **Retrieval-Augmented Generation (RAG)**.

- **Motivo principal:** La mayor√≠a de las consultas (‚âà 80 %) son repetitivas y dependen de informaci√≥n actualizada del negocio (estado de pedidos, pol√≠ticas de devoluci√≥n, cat√°logo).  
  Un RAG permite que el modelo base no requiera reentrenamiento cada vez que cambian los datos: solo necesita conectarse a una base de conocimiento din√°mica.


## 2Ô∏è‚É£ Por qu√© la elecci√≥n del modelo
- **Precisi√≥n y fluidez:** Un LLM grande ofrece lenguaje natural y tono emp√°tico para responder en m√∫ltiples canales (chat, email, redes sociales).
- **Costo / eficiencia:** En lugar de un *fine-tuned* propietario ‚Äîque implicar√≠a entrenamiento continuo y costo elevado‚Äî el enfoque RAG permite usar el modelo tal cual, complementado con datos internos indexados.
- **Escalabilidad:** El mismo modelo puede atender picos de miles de consultas diarias mediante *autoscaling* en la nube.
- **Privacidad:** Es posible tener un control total de los datos al usar con una infraestructura propia en la nube.


## 3Ô∏è‚É£ Arquitectura propuesta  

![Imagen_](https://github.com/user-attachments/assets/1118ea75-2b94-4192-bf97-d3ed4f5a29bb)

## ‚öôÔ∏è Tecnolog√≠as Seleccionadas y Justificaci√≥n

### üß© Gateway + API
El **gateway** gestiona el tr√°fico y la seguridad; la **API (FastAPI)** recibe la solicitud y la pasa al orquestador.

- Esta separaci√≥n permite **escalar** y **asegurar** el sistema, dado el r√°pido crecimuiento se recomienda separar estos roles.

### üîó LangChain + FastAPI
Combina la **orquestaci√≥n de flujos de IA** de **LangChain** con la **velocidad y facilidad de despliegue** de **FastAPI**, ofreciendo una API robusta, escalable y de alta disponibilidad para integrar el modelo con los distintos canales de comunicaci√≥n.

### üóÇÔ∏è FAISS
Librer√≠a **open source** optimizada para **b√∫squedas vectoriales r√°pidas**.  
Permite mantener **control total de los datos** y **reducir costos**, ideal para gestionar el √≠ndice sem√°ntico de productos y pedidos sin depender de servicios de terceros.

### ü§ñ Llama 3
Modelo de lenguaje **open source** de alto rendimiento que brinda **privacidad y personalizaci√≥n** al ejecutarse en una nube privada.  
Ofrece **calidad de generaci√≥n cercana a GPT-4** con la flexibilidad de *fine-tuning* y **costos predecibles**.


- **Integraci√≥n con base de datos:**  
  - Cat√°logo de productos, informaci√≥n de env√≠os y estados de pedido se almacenan en una base de datos relacional/NoSQL y se indexan en un motor vectorial para consultas en tiempo real.  
  - El modelo consulta estos datos mediante RAG antes de redactar la respuesta.
- **Modo de operaci√≥n:**  
  - Para preguntas de estado de pedido, una capa de l√≥gica de negocio valida identidad y obtiene datos exactos.  
  - Para consultas complejas (20 %), el sistema deriva autom√°ticamente a un agente humano, entregando el contexto de la conversaci√≥n.


## 4Ô∏è‚É£ Justificaci√≥n Final

- **Costo:**  
  Uso de un **LLM open source (Llama 3)** junto con un √≠ndice vectorial **FAISS** permite **evitar tarifas por token** y mantener **costos predecibles**.  
  Se paga √∫nicamente por la infraestructura en la nube, que puede dimensionarse seg√∫n la demanda.

- **Escalabilidad:**  
  La arquitectura combina **Gateway + API (FastAPI)** con un orquestador en **LangChain**, facilitando el *autoscaling* en la nube.  
  Esto permite manejar miles de consultas simult√°neas, con **balanceo de carga** y **cacheo de respuestas frecuentes** para optimizar recursos.

- **Mantenibilidad:**  
  La base de conocimiento se actualiza din√°micamente en **FAISS**, sin necesidad de reentrenar el modelo.  
  La separaci√≥n de capas (Gateway, API, Orquestador y Vector DB) simplifica actualizaciones y despliegues continuos.

- **Privacidad y Control de Datos:**  
  **Llama 3** puede ejecutarse en una nube privada, asegurando que las conversaciones y datos de clientes permanezcan bajo control total, clave para cumplir regulaciones.

- **Calidad de Respuesta:**  
  **Llama 3**, integrado con LangChain, ofrece **lenguaje natural, empat√≠a y soporte multicanal**, garantizando interacciones de alta calidad.  
  Adem√°s, el orquestador identifica consultas complejas y **deriva autom√°ticamente a un agente humano** con el contexto completo para una atenci√≥n sin fricciones.

---


## Fase 2 ‚Äì Evaluaci√≥n de Fortalezas, Limitaciones y Riesgos √âticos

### üí™ Fortalezas
- **Reducci√≥n del tiempo de respuesta:**  
  El sistema puede responder en segundos, disminuyendo el promedio de 24 horas a casi tiempo real.
- **Disponibilidad 24/7:**  
  La arquitectura en la nube permite atender consultas sin interrupciones, incluso en picos de demanda.
- **Cobertura de consultas repetitivas (~80 %):**  
  El orquestador con RAG (LangChain + FAISS) recupera informaci√≥n precisa del cat√°logo y pedidos de EcoMarket.
- **Escalabilidad y costos controlados:**  
  FAISS y Llama 3 autohospedado ofrecen independencia de tarifas por token y facilitan el crecimiento seg√∫n demanda.
- **Privacidad y control de datos:**  
  Al ejecutar Llama 3 en infraestructura privada, EcoMarket mantiene la propiedad de los datos sensibles.

### ‚ö†Ô∏è Limitaciones
- **Casos complejos (~20 %):**  
  Requieren empat√≠a y juicio humano (quejas graves, conflictos de reembolso). 
- **Dependencia de la base de conocimiento:**  
  Si FAISS contiene informaci√≥n desactualizada o err√≥nea, el modelo puede devolver respuestas incorrectas.
- **Mantenimiento de infraestructura:**  
  Ejecutar Llama 3 en la nube implica monitoreo de GPUs, actualizaciones de seguridad y optimizaci√≥n de costos.
- **Idioma y matices culturales:**  
  Aunque Llama 3 es multiling√ºe, podr√≠a cometer errores sutiles en expresiones locales o tonos espec√≠ficos.

### üõë Riesgos √âticos

1. **Alucinaciones:**  
   El modelo podr√≠a inventar informaci√≥n sobre pedidos o caracter√≠sticas de productos.  
   - *Mitigaci√≥n:* Validar datos cr√≠ticos (estado de pedido, precios) con reglas de negocio antes de enviar la respuesta.

2. **Sesgo:**  
   Los datos de entrenamiento pueden contener sesgos que generen respuestas preferenciales o discriminatorias.  
   - *Mitigaci√≥n:* Monitoreo constante, pruebas de equidad y ajuste de *prompts*.

3. **Privacidad de Datos:**  
   El sistema maneja direcciones, historial de compras y datos personales.  
   - *Mitigaci√≥n:* Cifrado en tr√°nsito y reposo, anonimizaci√≥n de logs, control estricto de acceso, y no-retenci√≥n en servicios externos.

4. **Impacto Laboral:**  
   La automatizaci√≥n podr√≠a reducir la necesidad de agentes humanos.  
   - *Mitigaci√≥n:* Enfocar el proyecto en **empoderar** a los agentes, delegando en la IA las tareas repetitivas y permitiendo que el personal se centre en casos complejos o de alto valor.

---

**Conclusi√≥n:**  
La soluci√≥n basada en **LangChain + FastAPI, FAISS y Llama 3** es potente para reducir tiempos de respuesta y manejar la mayor√≠a de las consultas.  
Sin embargo, requiere una estrategia clara de **supervisi√≥n humana, gobernanza de datos y gesti√≥n del cambio** para mitigar riesgos √©ticos y preservar la calidad del servicio.