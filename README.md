# Taller AI Generativa
Este repositorio contiene el material y el c√≥digo del taller ‚ÄúOptimizaci√≥n de la Atenci√≥n al Cliente en E-commerce con IA Generativa‚Äù, basado en el caso de estudio de la empresa ficticia "EcoMarket".


# Fase 1 ‚Äì Selecci√≥n y Justificaci√≥n del Modelo de IA

## 1Ô∏è‚É£ Tipo de modelo propuesto
Optar√≠a por un **LLM de prop√≥sito general** , en este caso el *Llama 3* combinado con un enfoque de **Retrieval-Augmented Generation (RAG)**.

- **Motivo principal:** La mayor√≠a de las consultas (‚âà 80 %) son repetitivas y dependen de informaci√≥n actualizada del negocio (estado de pedidos, pol√≠ticas de devoluci√≥n, cat√°logo).  
  Un RAG permite que el modelo base no requiera reentrenamiento cada vez que cambian los datos: solo necesita conectarse a una base de conocimiento din√°mica.


## 2Ô∏è‚É£ Por qu√© la elecci√≥n del modelo
- **Precisi√≥n y fluidez:** Un LLM grande ofrece lenguaje natural y tono emp√°tico para responder en m√∫ltiples canales (chat, email, redes sociales).
- **Costo / eficiencia:** En lugar de un *fine-tuned* propietario ‚Äîque implicar√≠a entrenamiento continuo y costo elevado‚Äî el enfoque RAG permite usar el modelo tal cual, complementado con datos internos indexados.
- **Escalabilidad:** El mismo modelo puede atender picos de miles de consultas diarias mediante *autoscaling* en la nube.
- **Privacidad:** Es posible tener un control total de los datos al usar con una infraestructura propia en la nube.


## 3Ô∏è‚É£ Arquitectura propuesta  

![Imagen_](https://github.com/user-attachments/assets/1118ea75-2b94-4192-bf97-d3ed4f5a29bb)

## ‚öôÔ∏è Tecnolog√≠as Seleccionadas y Justificaci√≥n

### üß© Gateway + API
El **gateway** gestiona el tr√°fico y la seguridad; la **API (FastAPI)** recibe la solicitud y la pasa al orquestador.

- Esta separaci√≥n permite **escalar** y **asegurar** el sistema, dado el r√°pido crecimuiento se recomienda separar estos roles.

### üîó LangChain + FastAPI
Combina la **orquestaci√≥n de flujos de IA** de **LangChain** con la **velocidad y facilidad de despliegue** de **FastAPI**, ofreciendo una API robusta, escalable y de alta disponibilidad para integrar el modelo con los distintos canales de comunicaci√≥n.

### üóÇÔ∏è FAISS
Librer√≠a **open source** optimizada para **b√∫squedas vectoriales r√°pidas**.  
Permite mantener **control total de los datos** y **reducir costos**, ideal para gestionar el √≠ndice sem√°ntico de productos y pedidos sin depender de servicios de terceros.

### ü§ñ Llama 3
Modelo de lenguaje **open source** de alto rendimiento que brinda **privacidad y personalizaci√≥n** al ejecutarse en una nube privada.  
Ofrece **calidad de generaci√≥n cercana a GPT-4** con la flexibilidad de *fine-tuning* y **costos predecibles**.


- **Integraci√≥n con base de datos:**  
  - Cat√°logo de productos, informaci√≥n de env√≠os y estados de pedido se almacenan en una base de datos relacional/NoSQL y se indexan en un motor vectorial para consultas en tiempo real.  
  - El modelo consulta estos datos mediante RAG antes de redactar la respuesta.
- **Modo de operaci√≥n:**  
  - Para preguntas de estado de pedido, una capa de l√≥gica de negocio valida identidad y obtiene datos exactos.  
  - Para consultas complejas (20 %), el sistema deriva autom√°ticamente a un agente humano, entregando el contexto de la conversaci√≥n.


## 4Ô∏è‚É£ Justificaci√≥n Final

- **Costo:**  
  Uso de un **LLM open source (Llama 3)** junto con un √≠ndice vectorial **FAISS** permite **evitar tarifas por token** y mantener **costos predecibles**.  
  Se paga √∫nicamente por la infraestructura en la nube, que puede dimensionarse seg√∫n la demanda.

- **Escalabilidad:**  
  La arquitectura combina **Gateway + API (FastAPI)** con un orquestador en **LangChain**, facilitando el *autoscaling* en la nube.  
  Esto permite manejar miles de consultas simult√°neas, con **balanceo de carga** y **cacheo de respuestas frecuentes** para optimizar recursos.

- **Mantenibilidad:**  
  La base de conocimiento se actualiza din√°micamente en **FAISS**, sin necesidad de reentrenar el modelo.  
  La separaci√≥n de capas (Gateway, API, Orquestador y Vector DB) simplifica actualizaciones y despliegues continuos.

- **Privacidad y Control de Datos:**  
  **Llama 3** puede ejecutarse en una nube privada, asegurando que las conversaciones y datos de clientes permanezcan bajo control total, clave para cumplir regulaciones.

- **Calidad de Respuesta:**  
  **Llama 3**, integrado con LangChain, ofrece **lenguaje natural, empat√≠a y soporte multicanal**, garantizando interacciones de alta calidad.  
  Adem√°s, el orquestador identifica consultas complejas y **deriva autom√°ticamente a un agente humano** con el contexto completo para una atenci√≥n sin fricciones.

---
